{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNRLIOXqi0hpKpMaom4dB0N"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["pip install transformers torch accelerate llama-index arxiv pypdf\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zT49eV73qH7o","executionInfo":{"status":"ok","timestamp":1742957363905,"user_tz":-60,"elapsed":138656,"user":{"displayName":"Taleb Sid elmoktar","userId":"07952132830249962471"}},"outputId":"e13bb9e2-6e17-46a1-ec0c-15ec6ca4c48c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.5.2)\n","Collecting llama-index\n","  Downloading llama_index-0.12.25-py3-none-any.whl.metadata (12 kB)\n","Collecting arxiv\n","  Downloading arxiv-2.1.3-py3-none-any.whl.metadata (6.1 kB)\n","Collecting pypdf\n","  Downloading pypdf-5.4.0-py3-none-any.whl.metadata (7.3 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.29.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n","Collecting llama-index-agent-openai<0.5.0,>=0.4.0 (from llama-index)\n","  Downloading llama_index_agent_openai-0.4.6-py3-none-any.whl.metadata (727 bytes)\n","Collecting llama-index-cli<0.5.0,>=0.4.1 (from llama-index)\n","  Downloading llama_index_cli-0.4.1-py3-none-any.whl.metadata (1.5 kB)\n","Collecting llama-index-core<0.13.0,>=0.12.25 (from llama-index)\n","  Downloading llama_index_core-0.12.25-py3-none-any.whl.metadata (2.5 kB)\n","Collecting llama-index-embeddings-openai<0.4.0,>=0.3.0 (from llama-index)\n","  Downloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl.metadata (684 bytes)\n","Collecting llama-index-indices-managed-llama-cloud>=0.4.0 (from llama-index)\n","  Downloading llama_index_indices_managed_llama_cloud-0.6.9-py3-none-any.whl.metadata (3.6 kB)\n","Collecting llama-index-llms-openai<0.4.0,>=0.3.0 (from llama-index)\n","  Downloading llama_index_llms_openai-0.3.27-py3-none-any.whl.metadata (3.3 kB)\n","Collecting llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0 (from llama-index)\n","  Downloading llama_index_multi_modal_llms_openai-0.4.3-py3-none-any.whl.metadata (726 bytes)\n","Collecting llama-index-program-openai<0.4.0,>=0.3.0 (from llama-index)\n","  Downloading llama_index_program_openai-0.3.1-py3-none-any.whl.metadata (764 bytes)\n","Collecting llama-index-question-gen-openai<0.4.0,>=0.3.0 (from llama-index)\n","  Downloading llama_index_question_gen_openai-0.3.0-py3-none-any.whl.metadata (783 bytes)\n","Collecting llama-index-readers-file<0.5.0,>=0.4.0 (from llama-index)\n","  Downloading llama_index_readers_file-0.4.7-py3-none-any.whl.metadata (5.4 kB)\n","Collecting llama-index-readers-llama-parse>=0.4.0 (from llama-index)\n","  Downloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl.metadata (3.6 kB)\n","Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index) (3.9.1)\n","Collecting feedparser~=6.0.10 (from arxiv)\n","  Downloading feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\n","Collecting sgmllib3k (from feedparser~=6.0.10->arxiv)\n","  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: openai>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.68.2)\n","Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.25->llama-index) (2.0.39)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (3.11.14)\n","Collecting dataclasses-json (from llama-index-core<0.13.0,>=0.12.25->llama-index)\n","  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n","Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (1.2.18)\n","Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.13.0,>=0.12.25->llama-index)\n","  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n","Collecting filetype<2.0.0,>=1.2.0 (from llama-index-core<0.13.0,>=0.12.25->llama-index)\n","  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n","Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (0.28.1)\n","Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (1.6.0)\n","Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (11.1.0)\n","Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (2.10.6)\n","Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (9.0.0)\n","Collecting tiktoken>=0.3.3 (from llama-index-core<0.13.0,>=0.12.25->llama-index)\n","  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n","Collecting typing-inspect>=0.8.0 (from llama-index-core<0.13.0,>=0.12.25->llama-index)\n","  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (1.17.2)\n","Collecting llama-cloud<0.2.0,>=0.1.13 (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index)\n","  Downloading llama_cloud-0.1.16-py3-none-any.whl.metadata (902 bytes)\n","Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (4.13.3)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.2.2)\n","Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index)\n","  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n","Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n","  Downloading llama_parse-0.6.4.post1-py3-none-any.whl.metadata (6.9 kB)\n","Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (8.1.8)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (1.4.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (6.2.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (0.3.0)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (1.18.3)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.6)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.25->llama-index) (4.9.0)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.25->llama-index) (1.0.7)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.25->llama-index) (0.14.0)\n","Collecting llama-cloud-services>=0.6.4 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n","  Downloading llama_cloud_services-0.6.8-py3-none-any.whl.metadata (2.9 kB)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.9.0)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (0.9.0)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.3.1)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.25->llama-index) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.25->llama-index) (2.27.2)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.25->llama-index) (3.1.1)\n","Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.25->llama-index)\n","  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n","Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.13.0,>=0.12.25->llama-index)\n","  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2025.1)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2025.1)\n","Collecting python-dotenv<2.0.0,>=1.0.1 (from llama-cloud-services>=0.6.4->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n","  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (1.17.0)\n","Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading llama_index-0.12.25-py3-none-any.whl (7.0 kB)\n","Downloading arxiv-2.1.3-py3-none-any.whl (11 kB)\n","Downloading pypdf-5.4.0-py3-none-any.whl (302 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m302.3/302.3 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading feedparser-6.0.11-py3-none-any.whl (81 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading llama_index_agent_openai-0.4.6-py3-none-any.whl (13 kB)\n","Downloading llama_index_cli-0.4.1-py3-none-any.whl (28 kB)\n","Downloading llama_index_core-0.12.25-py3-none-any.whl (1.6 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl (6.2 kB)\n","Downloading llama_index_indices_managed_llama_cloud-0.6.9-py3-none-any.whl (14 kB)\n","Downloading llama_index_llms_openai-0.3.27-py3-none-any.whl (16 kB)\n","Downloading llama_index_multi_modal_llms_openai-0.4.3-py3-none-any.whl (5.9 kB)\n","Downloading llama_index_program_openai-0.3.1-py3-none-any.whl (5.3 kB)\n","Downloading llama_index_question_gen_openai-0.3.0-py3-none-any.whl (2.9 kB)\n","Downloading llama_index_readers_file-0.4.7-py3-none-any.whl (40 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl (2.5 kB)\n","Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n","Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n","Downloading llama_cloud-0.1.16-py3-none-any.whl (251 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m251.3/251.3 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading llama_parse-0.6.4.post1-py3-none-any.whl (4.9 kB)\n","Downloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n","Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n","Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n","Downloading llama_cloud_services-0.6.8-py3-none-any.whl (29 kB)\n","Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n","Building wheels for collected packages: sgmllib3k\n","  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6047 sha256=47de53f19716b53269607cd0f3a208fae1695e4155b6efa7e9659a757f16055e\n","  Stored in directory: /root/.cache/pip/wheels/3b/25/2a/105d6a15df6914f4d15047691c6c28f9052cc1173e40285d03\n","Successfully built sgmllib3k\n","Installing collected packages: striprtf, sgmllib3k, filetype, dirtyjson, python-dotenv, pypdf, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, mypy-extensions, marshmallow, feedparser, typing-inspect, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, arxiv, nvidia-cusolver-cu12, llama-cloud, dataclasses-json, llama-index-core, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-cloud-services, llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-readers-llama-parse, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed arxiv-2.1.3 dataclasses-json-0.6.7 dirtyjson-1.0.8 feedparser-6.0.11 filetype-1.2.0 llama-cloud-0.1.16 llama-cloud-services-0.6.8 llama-index-0.12.25 llama-index-agent-openai-0.4.6 llama-index-cli-0.4.1 llama-index-core-0.12.25 llama-index-embeddings-openai-0.3.1 llama-index-indices-managed-llama-cloud-0.6.9 llama-index-llms-openai-0.3.27 llama-index-multi-modal-llms-openai-0.4.3 llama-index-program-openai-0.3.1 llama-index-question-gen-openai-0.3.0 llama-index-readers-file-0.4.7 llama-index-readers-llama-parse-0.4.0 llama-parse-0.6.4.post1 marshmallow-3.26.1 mypy-extensions-1.0.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pypdf-5.4.0 python-dotenv-1.1.0 sgmllib3k-1.0.0 striprtf-0.0.26 tiktoken-0.9.0 typing-inspect-0.9.0\n"]}]},{"cell_type":"code","source":["import os\n","import torch\n","import PyPDF2\n","from transformers import AutoModelForCausalLM, AutoTokenizer\n","from llama_index.core import (\n","    VectorStoreIndex,\n","    ServiceContext\n",")\n","from llama_index.llms.huggingface import HuggingFaceLLM\n","from llama_index.core.prompts import PromptTemplate\n","\n","def extract_pdf_text(pdf_path):\n","    \"\"\"\n","    Extract text from PDF using PyPDF2\n","\n","    Args:\n","        pdf_path (str): Path to the PDF file\n","\n","    Returns:\n","        str: Extracted text from the PDF\n","    \"\"\"\n","    with open(pdf_path, 'rb') as file:\n","        reader = PyPDF2.PdfReader(file)\n","\n","        # Extract text from all pages\n","        full_text = []\n","        for page in reader.pages:\n","            full_text.append(page.extract_text())\n","\n","        return \"\\n\".join(full_text)\n","\n","def summarize_pdf(pdf_path, model_name=\"facebook/opt-350m\"):\n","    \"\"\"\n","    Summarize PDF using open-source LLM\n","\n","    Args:\n","        pdf_path (str): Path to the PDF file\n","        model_name (str): Hugging Face model to use\n","\n","    Returns:\n","        dict: Comprehensive and section summaries\n","    \"\"\"\n","    # Extract text from PDF\n","    pdf_text = extract_pdf_text(pdf_path)\n","\n","    # Configure device\n","    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","    # Load tokenizer and model\n","    tokenizer = AutoTokenizer.from_pretrained(model_name)\n","    model = AutoModelForCausalLM.from_pretrained(\n","        model_name,\n","        device_map=device,\n","        torch_dtype=torch.float16 if device == \"cuda\" else torch.float32\n","    )\n","\n","    # Configure LLamaIndex LLM\n","    llm = HuggingFaceLLM(\n","        model=model,\n","        tokenizer=tokenizer,\n","        context_window=2048,\n","        max_new_tokens=512,\n","        generate_kwargs={\"temperature\": 0.1, \"do_sample\": False}\n","    )\n","\n","    # Comprehensive summary prompt\n","    comprehensive_prompt = PromptTemplate(\n","        \"Provide a detailed academic-style summary of this research paper. \"\n","        \"Include key points about the research question, methodology, \"\n","        \"key findings, and potential implications:\\n\\n{context}\\n\\n\"\n","        \"Comprehensive Summary:\"\n","    )\n","\n","    # Section summary prompt\n","    section_prompt = PromptTemplate(\n","        \"Summarize the following section of the research paper. \"\n","        \"Focus on the main ideas and critical information:\\n\\n{context}\\n\\n\"\n","        \"Section Summary:\"\n","    )\n","\n","    # Generate comprehensive summary\n","    comprehensive_prompt_filled = comprehensive_prompt.format(context=pdf_text[:4000])\n","    comprehensive_summary = llm.complete(comprehensive_prompt_filled)\n","\n","    # Generate section summaries (split text into chunks)\n","    section_summaries = []\n","    text_chunks = [pdf_text[i:i+2000] for i in range(0, len(pdf_text), 2000)]\n","    for chunk in text_chunks[:3]:  # Limit to first 3 chunks\n","        section_prompt_filled = section_prompt.format(context=chunk)\n","        section_summary = llm.complete(section_prompt_filled)\n","        section_summaries.append(str(section_summary))\n","\n","    return {\n","        \"comprehensive_summary\": str(comprehensive_summary),\n","        \"section_summaries\": section_summaries\n","    }\n","\n","def main():\n","    pdf_path = \"./sample_data/2312.00812.pdf\"\n","\n","    try:\n","        summaries = summarize_pdf(pdf_path)\n","\n","        print(\"ğŸ” Comprehensive Summary:\")\n","        print(summaries['comprehensive_summary'])\n","\n","        print(\"\\nğŸ“‹ Section Summaries:\")\n","        for idx, summary in enumerate(summaries['section_summaries'], 1):\n","            print(f\"Section {idx}:\\n{summary}\\n{'='*50}\\n\")\n","\n","    except Exception as e:\n","        print(f\"Error during PDF summarization: {e}\")\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"id":"F1mdpPkKqaMW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743034924241,"user_tz":-60,"elapsed":437580,"user":{"displayName":"Taleb Sid elmoktar","userId":"07952132830249962471"}},"outputId":"13e3c0fe-2eae-4eac-a3e3-5f69fee0fa2c"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["ğŸ” Comprehensive Summary:\n","\n","The present study investigates the impact of the use of large language models (LLMs) in autonomous driving. The study is based on a simulation of a real-world autonomous vehicle (AV) system, which is equipped with a large number of LLMs. The study is based on a simulation of a real-world autonomous vehicle (AV) system, which is equipped with a large number of LLMs. The study is based on a simulation of a real-world autonomous vehicle (AV) system, which is equipped with a large number of LLMs. The study is based on a simulation of a real-world autonomous vehicle (AV) system, which is equipped with a large number of LLMs. The study is based on a simulation of a real-world autonomous vehicle (AV) system, which is equipped with a large number of LLMs. The study is based on a simulation of a real-world autonomous vehicle (AV) system, which is equipped with a large number of LLMs. The study is based on a simulation of a real-world autonomous vehicle (AV) system, which is equipped with a large number of LLMs. The study is based on a simulation of a real-world autonomous vehicle (AV) system, which is equipped with a large number of LLMs. The study is based on a simulation of a real-world autonomous vehicle (AV) system, which is equipped with a large number of LLMs. The study is based on a simulation of a real-world autonomous vehicle (AV) system, which is equipped with a large number of LLMs. The study is based on a simulation of a real-world autonomous vehicle (AV) system, which is equipped with a large number of LLMs. The study is based on a simulation of a real-world autonomous vehicle (AV) system, which is equipped with a large number of LLMs. The study is based on a simulation of a real-world autonomous vehicle (AV) system, which is equipped with a large number of LLMs. The study is based on a simulation of a real-world autonomous vehicle (AV) system, which is equipped with a large number of LLMs. The study is based on a simulation of a real-world autonomous vehicle (AV) system, which is equipped with a large number of LLMs. The study is based on a simulation of a real-world autonomous vehicle (AV) system, which is equipped with a large number of LLMs. The study is based on a simulation of a real\n","\n","ğŸ“‹ Section Summaries:\n","Section 1:\n","\n","The aim of this paper is to present a new approach to the design of autonomous\n","vehicles (AVs) that is based on the use of large language models (LLMs) to\n","assist in the design of autonomous vehicles. The proposed approach is based on the\n","conclusion that the LLM-based approach can be used to design autonomous vehicles\n","with a wide range of safety and safety features. The proposed approach is based on the\n","conclusion that the LLM-based approach can be used to design autonomous vehicles with a\n","wide range of safety and safety features. The proposed approach is based on the\n","conclusion that the LLM-based approach can be used to design autonomous vehicles with a\n","wide range of safety and safety features. The proposed approach is based on the\n","conclusion that the LLM-based approach can be used to design autonomous vehicles with a\n","wide range of safety and safety features. The proposed approach is based on the\n","conclusion that the LLM-based approach can be used to design autonomous vehicles with a\n","wide range of safety and safety features. The proposed approach is based on the\n","conclusion that the LLM-based approach can be used to design autonomous vehicles with a\n","wide range of safety and safety features. The proposed approach is based on the\n","conclusion that the LLM-based approach can be used to design autonomous vehicles with a\n","wide range of safety and safety features. The proposed approach is based on the\n","conclusion that the LLM-based approach can be used to design autonomous vehicles with a\n","wide range of safety and safety features. The proposed approach is based on the\n","conclusion that the LLM-based approach can be used to design autonomous vehicles with a\n","wide range of safety and safety features. The proposed approach is based on the\n","conclusion that the LLM-based approach can be used to design autonomous vehicles with a\n","wide range of safety and safety features. The proposed approach is based on the\n","conclusion that the LLM-based approach can be used to design autonomous vehicles with a\n","wide range of safety and safety features. The proposed approach is based on the\n","conclusion that the LLM-based approach can be used to design autonomous vehicles with a\n","wide range of safety and safety features. The proposed approach is based on the\n","conclusion that the LLM-based approach can be used to design autonomous vehicles with a\n","wide range of safety and safety features. The proposed approach is based on the\n","\n","==================================================\n","\n","Section 2:\n","\n","\n","The A V software pipeline is a set of software components that are used to perform a variety of\n","autonomous driving tasks. The A V software pipeline is a set of software components that are used to\n","perform a variety of autonomous driving tasks. The A V software pipeline is a set of software components\n","that are used to perform a variety of autonomous driving tasks. The A V software pipeline is a\n","set of software components that are used to perform a variety of autonomous driving tasks. The A V\n","software pipeline is a set of software components that are used to perform a variety of autonomous driving\n","tasks. The A V software pipeline is a set of software components that are used to perform a variety of\n","autonomous driving tasks. The A V software pipeline is a set of software components that are used to perform a\n","variety of autonomous driving tasks. The A V software pipeline is a set of software components that are used to\n","perform a variety of autonomous driving tasks. The A V software pipeline is a set of software components\n","that are used to perform a variety of autonomous driving tasks. The A V software pipeline is a\n","set of software components that are used to perform a variety of autonomous driving tasks. The A V software\n","pipeline is a set of software components that are used to perform a variety of autonomous driving\n","tasks. The A V software pipeline is a set of software components that are used to perform a variety of\n","autonomous driving tasks. The A V software pipeline is a set of software components that are used to perform a\n","variety of autonomous driving tasks. The A V software pipeline is a set of software components that are used to\n","perform a variety of autonomous driving tasks. The A V software pipeline is a set of software components\n","that are used to perform a variety of autonomous driving tasks. The A V software pipeline is a set of software\n","pipeline that is used to perform a variety of autonomous driving tasks. The A V software pipeline is a\n","set of software components that are used to perform a variety of autonomous driving tasks. The A V software\n","pipeline is a set of software components that are used to perform a variety of autonomous driving\n","tasks. The A V software pipeline is a set of software components that are used to perform a variety of\n","autonomous driving tasks. The A V software pipeline is a set of software components that are used to perform a\n","variety of autonomous driving tasks. The A V software pipeline is a set\n","==================================================\n","\n","Section 3:\n","\n","The integration of LLMs such as GPT-3 (OpenAI, 2020) into AD has garnered significant attention\n","in recent years, revolutionizing natural language understanding and enhancing \n","\n","1. Introduction\n","The integration of LLMs such as GPT-3 (OpenAI, 2020) into AD has garnered significant attention\n","in recent years, revolutionizing natural language understanding and enhancing \n","\n","1.1 Introduction\n","The integration of LLMs such as GPT-3 (OpenAI, 2020) into AD has garnered significant attention\n","in recent years, revolutionizing natural language understanding and enhancing \n","\n","1.2 Introduction\n","The integration of LLMs such as GPT-3 (OpenAI, 2020) into AD has garnered significant attention\n","in recent years, revolutionizing natural language understanding and enhancing \n","\n","1.3 Introduction\n","The integration of LLMs such as GPT-3 (OpenAI, 2020) into AD has garnered significant attention\n","in recent years, revolutionizing natural language understanding and enhancing \n","\n","1.4 Introduction\n","The integration of LLMs such as GPT-3 (OpenAI, 2020) into AD has garnered significant attention\n","in recent years, revolutionizing natural language understanding and enhancing \n","\n","1.5 Introduction\n","The integration of LLMs such as GPT-3 (OpenAI, 2020) into AD has garnered significant attention\n","in recent years, revolutionizing natural language understanding and enhancing \n","\n","1.6 Introduction\n","The integration of LLMs such as GPT-3 (OpenAI, 2020) into AD has garnered significant attention\n","in recent years, revolutionizing natural language understanding and enhancing \n","\n","1.7 Introduction\n","The integration of LLMs such as GPT-3 (OpenAI, 2020) into AD has garnered significant attention\n","in recent years, revolutionizing natural language understanding and enhancing \n","\n","1.8 Introduction\n","The integration of LLMs such as GPT-3 (OpenAI, 2020) into AD has garnered significant attention\n","in recent years, revolutionizing natural language understanding and enhancing \n","\n","1.9 Introduction\n","The integration of LLMs such as GPT-3 (OpenAI, 2020) into AD has garnered significant attention\n","in recent years, revolutionizing natural language understanding and enhancing \n","\n","1.10 Introduction\n","The integration of LLMs such as GPT-3 (OpenAI, 2020) into AD has garnered significant attention\n","in recent years, revolutionizing natural language understanding and enhancing \n","\n","1\n","==================================================\n","\n"]}]},{"cell_type":"code","source":["pip install PyPDF2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x__wMn5l5yfX","executionInfo":{"status":"ok","timestamp":1743034482268,"user_tz":-60,"elapsed":5462,"user":{"displayName":"Taleb Sid elmoktar","userId":"07952132830249962471"}},"outputId":"5842725e-92c6-40d6-d56e-d68ab7f58a84"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting PyPDF2\n","  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n","Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: PyPDF2\n","Successfully installed PyPDF2-3.0.1\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"5jVbB0ih6BMi"},"execution_count":null,"outputs":[]}]}